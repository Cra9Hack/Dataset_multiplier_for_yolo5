{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec66ac4-6bc3-4aa3-abb1-7e79c36ece08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pic division started...\n",
      "pic division finished.\n",
      "detection started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../insectRecognition/yolov5/Big_Vlad_test_day22/yolov5n_size1856/weights/best.pt'], source=/home/cra9hack/Dropbox/PyProj/Untitled_Folder, data=../insectRecognition/yolov5/data/coco128.yaml, imgsz=[1856, 1856], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../insectRecognition/yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 ðŸš€ v6.2-208-g8236d881 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7948MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
      "image 1/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0.jpg: 1856x1664 (no detections), 10.8ms\n",
      "image 2/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_0_0.jpg: 1856x1856 (no detections), 12.8ms\n",
      "image 3/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_0_1856.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 4/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_0_3712.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 5/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_0_5568.jpg: 1856x1856 (no detections), 12.5ms\n",
      "image 6/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_0_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 7/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_0_9280.jpg: 1856x1856 (no detections), 11.9ms\n",
      "image 8/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_11136_0.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 9/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_11136_1856.jpg: 1856x1856 (no detections), 12.9ms\n",
      "image 10/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_11136_3712.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 11/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_11136_5568.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 12/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_11136_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 13/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_11136_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 14/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_1856_0.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 15/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_1856_1856.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 16/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_1856_3712.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 17/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_1856_5568.jpg: 1856x1856 (no detections), 13.1ms\n",
      "image 18/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_1856_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 19/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_1856_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 20/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_3712_0.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 21/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_3712_1856.jpg: 1856x1856 1 MoTe2_clean, 12.4ms\n",
      "image 22/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_3712_3712.jpg: 1856x1856 2 MoTe2_cleans, 12.1ms\n",
      "image 23/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_3712_5568.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 24/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_3712_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 25/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_3712_9280.jpg: 1856x1856 (no detections), 12.5ms\n",
      "image 26/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_5568_0.jpg: 1856x1856 (no detections), 11.9ms\n",
      "image 27/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_5568_1856.jpg: 1856x1856 2 MoTe2_cleans, 11.8ms\n",
      "image 28/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_5568_3712.jpg: 1856x1856 1 MoTe2_clean, 11.8ms\n",
      "image 29/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_5568_5568.jpg: 1856x1856 (no detections), 14.1ms\n",
      "image 30/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_5568_7424.jpg: 1856x1856 (no detections), 12.1ms\n",
      "image 31/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_5568_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 32/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_7424_0.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 33/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_7424_1856.jpg: 1856x1856 (no detections), 14.6ms\n",
      "image 34/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_7424_3712.jpg: 1856x1856 1 MoTe2_clean, 11.8ms\n",
      "image 35/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_7424_5568.jpg: 1856x1856 3 MoTe2_cleans, 11.8ms\n",
      "image 36/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_7424_7424.jpg: 1856x1856 1 MoTe2_clean, 12.9ms\n",
      "image 37/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_7424_9280.jpg: 1856x1856 (no detections), 12.2ms\n",
      "image 38/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_9280_0.jpg: 1856x1856 (no detections), 11.9ms\n",
      "image 39/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_9280_1856.jpg: 1856x1856 1 MoTe2_clean, 11.8ms\n",
      "image 40/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_9280_3712.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 41/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_9280_5568.jpg: 1856x1856 2 MoTe2_cleans, 12.9ms\n",
      "image 42/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_9280_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 43/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img0_9280_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 44/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1.jpg: 1664x1856 (no detections), 10.8ms\n",
      "image 45/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_0_0.jpg: 1856x1856 (no detections), 12.8ms\n",
      "image 46/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_0_11136.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 47/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_0_1856.jpg: 1856x1856 (no detections), 11.9ms\n",
      "image 48/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_0_3712.jpg: 1856x1856 (no detections), 12.5ms\n",
      "image 49/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_0_5568.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 50/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_0_7424.jpg: 1856x1856 (no detections), 12.9ms\n",
      "image 51/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_0_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 52/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_1856_0.jpg: 1856x1856 (no detections), 13.9ms\n",
      "image 53/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_1856_11136.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 54/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_1856_1856.jpg: 1856x1856 1 MoTe2_clean, 12.9ms\n",
      "image 55/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_1856_3712.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 56/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_1856_5568.jpg: 1856x1856 1 MoTe2_clean, 14.5ms\n",
      "image 57/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_1856_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 58/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_1856_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 59/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_3712_0.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 60/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_3712_11136.jpg: 1856x1856 (no detections), 12.4ms\n",
      "image 61/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_3712_1856.jpg: 1856x1856 2 MoTe2_cleans, 11.8ms\n",
      "image 62/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_3712_3712.jpg: 1856x1856 3 MoTe2_cleans, 11.8ms\n",
      "image 63/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_3712_5568.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 64/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_3712_7424.jpg: 1856x1856 2 MoTe2_cleans, 13.6ms\n",
      "image 65/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_3712_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 66/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_5568_0.jpg: 1856x1856 (no detections), 11.9ms\n",
      "image 67/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_5568_11136.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 68/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_5568_1856.jpg: 1856x1856 2 MoTe2_cleans, 12.5ms\n",
      "image 69/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_5568_3712.jpg: 1856x1856 1 MoTe2_clean, 11.8ms\n",
      "image 70/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_5568_5568.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 71/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_5568_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 72/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_5568_9280.jpg: 1856x1856 (no detections), 13.4ms\n",
      "image 73/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_7424_0.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 74/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_7424_11136.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 75/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_7424_1856.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 76/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_7424_3712.jpg: 1856x1856 1 MoTe2_clean, 11.8ms\n",
      "image 77/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_7424_5568.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 78/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_7424_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 79/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_7424_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 80/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_9280_0.jpg: 1856x1856 (no detections), 12.5ms\n",
      "image 81/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_9280_11136.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 82/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_9280_1856.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 83/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_9280_3712.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 84/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_9280_5568.jpg: 1856x1856 (no detections), 11.9ms\n",
      "image 85/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_9280_7424.jpg: 1856x1856 (no detections), 11.8ms\n",
      "image 86/86 /home/cra9hack/Dropbox/PyProj/Untitled_Folder/img1_9280_9280.jpg: 1856x1856 (no detections), 11.8ms\n",
      "Speed: 1.8ms pre-process, 12.1ms inference, 0.3ms NMS per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1m../insectRecognition/yolov5/runs/detect/exp65\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection finished.\n",
      "pic stitching started...\n",
      "pic stitching finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage import color, io, measure\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "import sys\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The program divides te image into smaller pieces, as the network was trained on smaller resolution pics. Currently it was trained in the 1864x1864 squares.\n",
    "To detect the flakes each image is divided into a grid of 1864x1864 images, with the margins cut off\n",
    "\"\"\"\n",
    "print(\"pic division started...\")\n",
    "def tile_label(filename, dir_in, dir_out, d):                #Funtion to divide the image, takes the filename, path for load and save and d- the size of the gid image, in this case 1864\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    img = Image.open(os.path.join(dir_in, filename))\n",
    "    #img = color.rgb2gray(img)\n",
    "    w, h = img.size\n",
    "    grid = product(range(0, h-h%d+1, d), range(0, w-w%d+1, d))  \n",
    "    for i, j in grid:\n",
    "        box = (j, i, j+d, i+d)\n",
    "        out = os.path.join(dir_out, f'{name}_{i}_{j}{ext}')       \n",
    "        img.crop(box).save(out)                              #cropping the box out of the original image\n",
    "       \n",
    "                                                            \n",
    "image_set = io.imread_collection('*.jpg')                    #collecting all images into a single list                                      \n",
    "for i, image in enumerate(image_set):    \n",
    "    tile_label(image_set.files[i][:-4]+'.jpg',\"\",\"\",1856)\n",
    "    \n",
    "print(\"pic division finished.\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "To detect images we used a yolov5n NN. This is the command that activates the detect.py script to detect flakes on the images cut out from the original one above.\n",
    "\"\"\"\n",
    "\n",
    "print(\"detection started...\")\n",
    "detect = \"python3 ../insectRecognition/yolov5/detect.py \"                                                        #yolov5 script for object detection\n",
    "#size = \"--img 1864 \"                                                                                             #the size of the image on which detection is performedimage size\n",
    "size = \"--img 1856 \"  \n",
    "#weights = \"--weights ../insectRecognition/yolov5/Big_Vlad_test_day10/yolov5n_size18645/weights/best.pt \"         #a path to the weights file, based on training\n",
    "weights = \"--weights ../insectRecognition/yolov5/Big_Vlad_test_day22/yolov5n_size1856/weights/best.pt \"\n",
    "source = \"--source \" + os.getcwd()                                                                               #a source of files on which the detection is to be performed (in this case it's a folder)\n",
    "\n",
    "os.system(detect+size+weights+source)                                                                            #detect flakes on each image\n",
    "print(\"detection finished.\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The last thing to do is to stitch the image with detected flakes back together, so it can be compared with the original one for an easy localization of the flakes\n",
    "\"\"\"\n",
    "print(\"pic stitching started...\")\n",
    "all_subdirs = [os.path.join(\"../insectRecognition/yolov5/runs/detect/\",d) for d in os.listdir('../insectRecognition/yolov5/runs/detect/.') ]\n",
    "latest_subdir = max(all_subdirs, key=os.path.getmtime)+\"/\"\n",
    "grid_collection = []\n",
    "image_set = io.imread_collection(latest_subdir+\"*\")\n",
    "for i, image in enumerate(image_set):\n",
    "    image_name = re.split(\"_\",image_set.files[i][:-4])\n",
    "    if len(image_name) == 1:\n",
    "        new_image_name = image_name[0]       \n",
    "        if grid_collection != []:            \n",
    "            for image in grid_collection:                \n",
    "                stitched_image.paste(Image.fromarray(image[0]),(int(image[1][2]),int(image[1][1])))\n",
    "                delete_path = image[1][0].replace(latest_subdir,\"\")+\"_\"+image[1][1]+\"_\"+image[1][2]+\".jpg\"\n",
    "                os.remove(delete_path)\n",
    "            save_path = image[1][0].replace(latest_subdir,\"\")\n",
    "            stitched_image.save(save_path+\"_detected.jpg\")\n",
    "        grid_collection = []\n",
    "        n = 0\n",
    "        size_determined = 0\n",
    "    else:\n",
    "        grid_collection.append([image,image_name])\n",
    "        if size_determined != True:\n",
    "            size = image_name[1]\n",
    "            size_determined = 1\n",
    "        if image_name[1] == size:\n",
    "            n = n+1\n",
    "        else:\n",
    "            img = Image.fromarray(image)\n",
    "            stitched_image_width = n*img.width\n",
    "            stitched_image_height = n*img.height\n",
    "            stitched_image = Image.new(\"RGB\", (stitched_image_width, stitched_image_height))\n",
    "            img.close()\n",
    "if grid_collection != []:\n",
    "    for image in grid_collection:                \n",
    "        stitched_image.paste(Image.fromarray(image[0]),(int(image[1][2]),int(image[1][1])))\n",
    "        delete_path = image[1][0].replace(latest_subdir,\"\")+\"_\"+image[1][1]+\"_\"+image[1][2]+\".jpg\"\n",
    "        os.remove(delete_path)\n",
    "    save_path = image[1][0].replace(latest_subdir,\"\")\n",
    "    stitched_image.save(save_path+\"_detected.jpg\")\n",
    "print(\"pic stitching finished\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c6261-b774-4267-bd04-9944a6f58065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79701e5d-8277-4044-9d5e-a3aafdde7409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
